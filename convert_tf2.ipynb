{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convert tf2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SKrHBITRokaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "ad82ec00-575e-4795-d6b7-1aa704e5d5ed"
      },
      "cell_type": "code",
      "source": [
        "!pip install tf-nightly-2.0-preview"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/5e/006d0b0c1b15038efef2ad749e26cb2398b9182a9db4234b979d7c734c6e/tf_nightly_2.0_preview-2.0.0.dev20190128-cp36-cp36m-manylinux1_x86_64.whl (75.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 75.4MB 410kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.32.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.1.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.11.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a0,>=1.13.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.13.0a20190128)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.14.6)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.13.0.dev2019012800)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.6.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf-nightly-2.0-preview) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf-nightly-2.0-preview) (3.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview) (40.6.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-2.0-preview) (2.8.0)\n",
            "Installing collected packages: tf-nightly-2.0-preview\n",
            "Successfully installed tf-nightly-2.0-preview-2.0.0.dev20190128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WXiLqASRo_bm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "98HyF5E0pPXn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UWalICUBpuGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f70e3a73-c2c3-4dc3-f6ee-ed233a830756"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1WE6YMJpv9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6100f687-bbf1-44ec-8ca6-8ed2d9f992f4"
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PMkEGOnUp3PC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b934211-59b6-402b-995a-ca764212a7c5"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oars1z1bp4KM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b8f9dcd-eec3-442c-8c3d-1712424fb447"
      },
      "cell_type": "code",
      "source": [
        "cd 'My Drive/'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e-wm9DV-p56E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8edb017-dd9d-4d57-9645-e7a5ed8f85d0"
      },
      "cell_type": "code",
      "source": [
        "cd py_files/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/py_files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NiPfpMMIp6-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "97622397-1668-42e5-c9db-9070d9cd5b47"
      },
      "cell_type": "code",
      "source": [
        "!tf_upgrade_v2 --infile v1.py --outfile v2.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO line 24:31: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 102:29: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 143:29: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 253:14: Renamed 'tf.contrib.saved_model.save_keras_model' to 'tf.keras.experimental.export'\n",
            "INFO line 268:29: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 300:14: Renamed 'tf.contrib.saved_model.save_keras_model' to 'tf.keras.experimental.export'\n",
            "INFO line 345:29: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 377:14: Renamed 'tf.contrib.saved_model.save_keras_model' to 'tf.keras.experimental.export'\n",
            "INFO line 410:29: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 420:14: Renamed 'tf.contrib.saved_model.save_keras_model' to 'tf.keras.experimental.export'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 0 errors that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report.txt'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-m3G7qeqCFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7806
        },
        "outputId": "1297df77-a493-40f2-a792-e5f1714dac77"
      },
      "cell_type": "code",
      "source": [
        "!cat v2.py"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"Cash Recognition for Visually Impaired FineTuned.ipynb\n",
            "\n",
            "Automatically generated by Colaboratory.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1tRWcagUABi_06_JJyWNjNvoL_FDfOHEY\n",
            "\"\"\"\n",
            "\n",
            "import os\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "import zipfile\n",
            "\n",
            "import tensorflow as tf\n",
            "\n",
            "from google.colab import drive\n",
            "\n",
            "#import tensorflow_hub as hub\n",
            "\n",
            "import math\n",
            "\n",
            "tf.keras.backend.set_session = tf.compat.v1.Session()\n",
            "\n",
            "drive.mount('/content/drive')\n",
            "\n",
            "\n",
            "\n",
            "local_zip = 'cash_full_data/full_data.zip' # local path of downloaded .zip file\n",
            "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
            "zip_ref.extractall('/tmp') # contents are extracted to '/tmp' folder\n",
            "zip_ref.close()\n",
            "\n",
            "base_dir = '/tmp/full_data'\n",
            "train_dir = os.path.join(base_dir, 'train') \n",
            "validation_dir = os.path.join(base_dir, 'valid')\n",
            "\n",
            "batch_size = 100\n",
            "epochs = 100\n",
            "IMG_SHAPE = 224 # Our training data will consists of images with width of 150 pixels and height of 150 pixels\n",
            "\n",
            "pre_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), alpha=1.0, depth_multiplier=1, include_top=False, weights='imagenet')\n",
            "\n",
            "for layer in pre_model.layers:\n",
            "    layer.trainable = False\n",
            "\n",
            "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
            "                    rescale=1./255, \n",
            "                    rotation_range=45, \n",
            "                    width_shift_range=.15, \n",
            "                    height_shift_range=.15, \n",
            "                    horizontal_flip=True, \n",
            "                    zoom_range=0.5\n",
            "                    )\n",
            "\n",
            "# train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
            "\n",
            "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
            "\n",
            "train_data_gen = train_image_generator.flow_from_directory(\n",
            "                                                batch_size=batch_size, \n",
            "                                                directory=train_dir, \n",
            "                                                shuffle=True, \n",
            "                                                class_mode='categorical',\n",
            "                                                target_size=(IMG_SHAPE,IMG_SHAPE))\n",
            "\n",
            "val_data_gen = validation_image_generator.flow_from_directory(batch_size=50, \n",
            "                                                              directory=validation_dir, \n",
            "                                                              class_mode='categorical',\n",
            "                                                              target_size=(IMG_SHAPE,IMG_SHAPE),shuffle=False) #(224,224)\n",
            "\n",
            "num_of_test_samples = 3334\n",
            "\n",
            "sample_training_images, _ = next(train_data_gen)\n",
            "\n",
            "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
            "def plotImages(images_arr):\n",
            "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
            "    axes = axes.flatten()\n",
            "    for img, ax in zip( images_arr, axes):\n",
            "        ax.imshow(img)\n",
            "    plt.tight_layout()\n",
            "    plt.show()\n",
            "\n",
            "plotImages(sample_training_images[:5])\n",
            "\n",
            "model_fine = tf.keras.models.Sequential()\n",
            "\n",
            "model_fine.add(pre_model)\n",
            "\n",
            "model_fine.add(tf.keras.layers.Flatten())\n",
            "\n",
            "model_fine.add(tf.keras.layers.Dense(64, activation='relu'))\n",
            "model_fine.add(tf.keras.layers.Dropout(0.4))\n",
            "model_fine.add(tf.keras.layers.Dense(32, activation='relu'))\n",
            "\n",
            "model_fine.add(tf.keras.layers.Dense(7, activation='softmax'))\n",
            "\n",
            "model_fine.summary()\n",
            "\n",
            "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
            "\n",
            "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=50, steps_per_epoch=20, validation_steps=20)\n",
            "\n",
            "model_fine.evaluate_generator(val_data_gen)\n",
            "\n",
            "acc = history.history['categorical_accuracy']\n",
            "val_acc = history.history['val_categorical_accuracy']\n",
            "\n",
            "loss = history.history['loss']\n",
            "val_loss = history.history['val_loss']\n",
            "\n",
            "epochs_range = range(50)\n",
            "\n",
            "plt.figure(figsize=(20, 8))\n",
            "plt.subplot(1, 2, 1)\n",
            "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
            "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
            "plt.legend(loc='lower right')\n",
            "plt.title('Training and Validation Accuracy')\n",
            "\n",
            "plt.subplot(1, 2, 2)\n",
            "plt.plot(epochs_range, loss, label='Training Loss')\n",
            "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
            "plt.legend(loc='upper right')\n",
            "plt.title('Training and Validation Loss')\n",
            "plt.show()\n",
            "\n",
            "model_fine.save(\"CashKeras-50-transfer-epoch-drpt-03-lr0001.h5\")\n",
            "\n",
            "pre_model.summary()\n",
            "\n",
            "position_layer = pre_model.get_layer('block_15_add')\n",
            "\n",
            "for layer in pre_model.layers:\n",
            "  layer.trainable = True\n",
            "\n",
            "all_layers = pre_model.layers\n",
            "for i in range(pre_model.layers.index(position_layer)):\n",
            "    all_layers[i].trainable = False\n",
            "\n",
            "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
            "\n",
            "model_fine.summary()\n",
            "\n",
            "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=50, steps_per_epoch=20, validation_steps=20)\n",
            "\n",
            "model_fine.evaluate_generator(val_data_gen)\n",
            "\n",
            "acc = history.history['categorical_accuracy']\n",
            "val_acc = history.history['val_categorical_accuracy']\n",
            "\n",
            "loss = history.history['loss']\n",
            "val_loss = history.history['val_loss']\n",
            "\n",
            "epochs_range = range(50)\n",
            "\n",
            "plt.figure(figsize=(20, 8))\n",
            "plt.subplot(1, 2, 1)\n",
            "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
            "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
            "plt.legend(loc='lower right')\n",
            "plt.title('Training and Validation Accuracy')\n",
            "\n",
            "plt.subplot(1, 2, 2)\n",
            "plt.plot(epochs_range, loss, label='Training Loss')\n",
            "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
            "plt.legend(loc='upper right')\n",
            "plt.title('Training and Validation Loss')\n",
            "plt.show()\n",
            "\n",
            "model_fine.save(\"CashKeras-50-finetune-epoch-drpt-03-lr0001.h5\")\n",
            "\n",
            "#tf.keras.models.save_model(model_fine, \"Models/keras200lr0001.h5\", include_optimizer=True)\n",
            "\n",
            "\n",
            "from sklearn.metrics import classification_report, confusion_matrix\n",
            "\n",
            "Y_pred = model_fine.predict_generator(val_data_gen)\n",
            "\n",
            "y_pred = np.argmax(Y_pred, axis=1)\n",
            "\n",
            "y_pred.shape\n",
            "\n",
            "print('Confusion Matrix')\n",
            "print(confusion_matrix(val_data_gen.classes, y_pred))\n",
            "\n",
            "cm = confusion_matrix(val_data_gen.classes, y_pred)\n",
            "\n",
            "val_data_gen.class_indices\n",
            "\n",
            "print('Classification Report')\n",
            "target_names = ['fifty', 'five', 'fivehundred', 'hundred', 'ten', 'thousand', 'twenty']\n",
            "print(classification_report(val_data_gen.classes, y_pred, target_names=target_names))\n",
            "\n",
            "import itertools\n",
            "\n",
            "from sklearn.metrics import confusion_matrix\n",
            "\n",
            "def plot_confusion_matrix(cm, classes,\n",
            "                          normalize=False,\n",
            "                          title='Confusion matrix',\n",
            "                          cmap=plt.cm.Blues):\n",
            "    \"\"\"\n",
            "    This function prints and plots the confusion matrix.\n",
            "    Normalization can be applied by setting `normalize=True`.\n",
            "    \"\"\"\n",
            "    if normalize:\n",
            "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
            "        print(\"Normalized confusion matrix\")\n",
            "    else:\n",
            "        print('Confusion matrix, without normalization')\n",
            "\n",
            "    print(cm)\n",
            "\n",
            "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
            "    plt.title(title)\n",
            "    plt.colorbar()\n",
            "    tick_marks = np.arange(len(classes))\n",
            "    plt.xticks(tick_marks, classes, rotation=45)\n",
            "    plt.yticks(tick_marks, classes)\n",
            "\n",
            "    fmt = '.2f' if normalize else 'd'\n",
            "    thresh = cm.max() / 2.\n",
            "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
            "        plt.text(j, i, format(cm[i, j], fmt),\n",
            "                 horizontalalignment=\"center\",\n",
            "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
            "\n",
            "    plt.ylabel('True label')\n",
            "    plt.xlabel('Predicted label')\n",
            "    plt.tight_layout()\n",
            "\n",
            "# Compute confusion matrix\n",
            "cnf_matrix = cm\n",
            "np.set_printoptions(precision=2)\n",
            "\n",
            "# Plot non-normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
            "                      title='Confusion matrix, without normalization')\n",
            "\n",
            "# Plot normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n",
            "                      title='Normalized confusion matrix')\n",
            "\n",
            "plt.show()\n",
            "\n",
            "cm\n",
            "\n",
            "output_path = tf.keras.experimental.export(model_fine, 'KerasCashFineTuned50/')\n",
            "\n",
            "#!tflite_convert --output_file=Cash.tflite --saved_model_dir=savedModel_cash100/1546849938\n",
            "\n",
            "pre_model.summary()\n",
            "\n",
            "position_layer = pre_model.get_layer('block_13_expand')\n",
            "\n",
            "for layer in pre_model.layers:\n",
            "  layer.trainable = True\n",
            "\n",
            "all_layers = pre_model.layers\n",
            "for i in range(pre_model.layers.index(position_layer)):\n",
            "    all_layers[i].trainable = False\n",
            "\n",
            "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.000001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
            "\n",
            "model_fine.summary()\n",
            "\n",
            "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=50, steps_per_epoch=20, validation_steps=20)\n",
            "\n",
            "model_fine.evaluate_generator(val_data_gen)\n",
            "\n",
            "acc = history.history['categorical_accuracy']\n",
            "val_acc = history.history['val_categorical_accuracy']\n",
            "\n",
            "loss = history.history['loss']\n",
            "val_loss = history.history['val_loss']\n",
            "\n",
            "epochs_range = range(50)\n",
            "\n",
            "plt.figure(figsize=(20, 8))\n",
            "plt.subplot(1, 2, 1)\n",
            "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
            "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
            "plt.legend(loc='lower right')\n",
            "plt.title('Training and Validation Accuracy')\n",
            "\n",
            "plt.subplot(1, 2, 2)\n",
            "plt.plot(epochs_range, loss, label='Training Loss')\n",
            "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
            "plt.legend(loc='upper right')\n",
            "plt.title('Training and Validation Loss')\n",
            "plt.show()\n",
            "\n",
            "model_fine.save(\"CashKeras-50-finetune_2-epoch-drpt-03-lr0001.h5\")\n",
            "\n",
            "output_path = tf.keras.experimental.export(model_fine, 'KerasCashFineTuned50_2/')\n",
            "\n",
            "Y_pred = model_fine.predict_generator(val_data_gen)\n",
            "y_pred = np.argmax(Y_pred, axis=1)\n",
            "\n",
            "print('Confusion Matrix')\n",
            "print(confusion_matrix(val_data_gen.classes, y_pred))\n",
            "\n",
            "cm = confusion_matrix(val_data_gen.classes, y_pred)\n",
            "\n",
            "print('Classification Report')\n",
            "target_names = ['fifty', 'five', 'fivehundred', 'hundred', 'ten', 'thousand', 'twenty']\n",
            "print(classification_report(val_data_gen.classes, y_pred, target_names=target_names))\n",
            "\n",
            "# Compute confusion matrix\n",
            "cnf_matrix = cm\n",
            "np.set_printoptions(precision=2)\n",
            "\n",
            "# Plot non-normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
            "                      title='Confusion matrix, without normalization')\n",
            "\n",
            "# Plot normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n",
            "                      title='Normalized confusion matrix')\n",
            "\n",
            "plt.show()\n",
            "\n",
            "output_path\n",
            "\n",
            "#!tflite_convert --output_file=Cash.tflite --saved_model_dir=KerasCashFineTuned50_2/1547020680\n",
            "\n",
            "pre_model.summary()\n",
            "\n",
            "position_layer = pre_model.get_layer('block_8_expand')\n",
            "\n",
            "for layer in pre_model.layers:\n",
            "  layer.trainable = True\n",
            "  \n",
            "all_layers = pre_model.layers\n",
            "for i in range(pre_model.layers.index(position_layer)):\n",
            "    all_layers[i].trainable = False\n",
            "\n",
            "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.0000001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
            "\n",
            "model_fine.summary()\n",
            "\n",
            "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=20, steps_per_epoch=20, validation_steps=20)\n",
            "\n",
            "model_fine.evaluate_generator(val_data_gen)\n",
            "\n",
            "acc = history.history['categorical_accuracy']\n",
            "val_acc = history.history['val_categorical_accuracy']\n",
            "\n",
            "loss = history.history['loss']\n",
            "val_loss = history.history['val_loss']\n",
            "\n",
            "epochs_range = range(20)\n",
            "\n",
            "plt.figure(figsize=(20, 8))\n",
            "plt.subplot(1, 2, 1)\n",
            "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
            "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
            "plt.legend(loc='lower right')\n",
            "plt.title('Training and Validation Accuracy')\n",
            "\n",
            "plt.subplot(1, 2, 2)\n",
            "plt.plot(epochs_range, loss, label='Training Loss')\n",
            "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
            "plt.legend(loc='upper right')\n",
            "plt.title('Training and Validation Loss')\n",
            "plt.show()\n",
            "\n",
            "model_fine.save(\"CashKeras-50-finetune_3-epoch-drpt-03-lr0001.h5\")\n",
            "\n",
            "output_path = tf.keras.experimental.export(model_fine, 'KerasCashFineTuned50_3/')\n",
            "\n",
            "Y_pred = model_fine.predict_generator(val_data_gen)\n",
            "y_pred = np.argmax(Y_pred, axis=1)\n",
            "\n",
            "print('Confusion Matrix')\n",
            "print(confusion_matrix(val_data_gen.classes, y_pred))\n",
            "\n",
            "cm = confusion_matrix(val_data_gen.classes, y_pred)\n",
            "\n",
            "print('Classification Report')\n",
            "target_names = ['fifty', 'five', 'fivehundred', 'hundred', 'ten', 'thousand', 'twenty']\n",
            "print(classification_report(val_data_gen.classes, y_pred, target_names=target_names))\n",
            "\n",
            "# Compute confusion matrix\n",
            "cnf_matrix = cm\n",
            "np.set_printoptions(precision=2)\n",
            "\n",
            "# Plot non-normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
            "                      title='Confusion matrix, without normalization')\n",
            "\n",
            "# Plot normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n",
            "                      title='Normalized confusion matrix')\n",
            "\n",
            "plt.show()\n",
            "\n",
            "for layer in pre_model.layers:\n",
            "  layer.trainable = True\n",
            "\n",
            "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.0000001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
            "\n",
            "model_fine.summary()\n",
            "\n",
            "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=50, steps_per_epoch=20, validation_steps=20)\n",
            "\n",
            "model_fine.evaluate_generator(val_data_gen)\n",
            "\n",
            "model_fine.save(\"CashKeras-50-finetune_all-epoch-drpt-03-lr0000001.h5\")\n",
            "\n",
            "output_path = tf.keras.experimental.export(model_fine, 'KerasCashFineTuned50_all/')\n",
            "\n",
            "Y_pred = model_fine.predict_generator(val_data_gen)\n",
            "y_pred = np.argmax(Y_pred, axis=1)\n",
            "\n",
            "print('Confusion Matrix')\n",
            "print(confusion_matrix(val_data_gen.classes, y_pred))\n",
            "\n",
            "cm = confusion_matrix(val_data_gen.classes, y_pred)\n",
            "\n",
            "print('Classification Report')\n",
            "target_names = ['fifty', 'five', 'fivehundred', 'hundred', 'ten', 'thousand', 'twenty']\n",
            "print(classification_report(val_data_gen.classes, y_pred, target_names=target_names))\n",
            "\n",
            "# Compute confusion matrix\n",
            "cnf_matrix = cm\n",
            "np.set_printoptions(precision=2)\n",
            "\n",
            "# Plot non-normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
            "                      title='Confusion matrix, without normalization')\n",
            "\n",
            "# Plot normalized confusion matrix\n",
            "plt.figure()\n",
            "plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n",
            "                      title='Normalized confusion matrix')\n",
            "\n",
            "plt.show()\n",
            "\n",
            "output_path\n",
            "\n",
            "#!tflite_convert --output_file=Cash.tflite --saved_model_dir=KerasCashFineTuned50_all/1547027314\n",
            "\n",
            "val_data_gen.class_indices\n",
            "\n",
            "train_data_gen.class_indices\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kDeWEAXjqNCl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}